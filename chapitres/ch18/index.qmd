# Réseaux neuronaux

<!-- paragraph -->

```{r setup, echo=FALSE}
knitr::opts_chunk$set(fig.path="ch18-figures/")
if(FALSE){
  knitr::knit("ch18-neural-networks.Rmd")
}
```

<!-- paragraph -->

Dans ce chapitre, nous explorerons plusieurs visualisations des données de l’algorithme d’apprentissage par descente de gradient pour les réseaux neuronaux.

<!-- paragraph -->

Plan du chapitre :

<!-- paragraph -->

- Nous commençons par simuler et visualiser quelques données 2D pour une classification binaire.
<!-- comment -->
- Nous montrons ensuite comment une fonction de classification en 2D peut être visualisée en calculant les prédictions sur une grille, puis en utilisant `geom_tile()` ou `geom_path()` avec des lignes de contour.
<!-- comment -->
- Nous calculons les prédictions du modèle linéaire et les mises à jour de la descente de gradient à l’aide d’un système simple de différenciation automatique (auto-grad).
<!-- comment -->
- Nous terminons en implémentant la descente de gradient pour un réseau neuronal, et en utilisant une visualisation interactive pour montrer comment les prédictions se précisent avec les itérations de l’algorithme d’apprentissage.

<!-- paragraph -->

## Visualisation des données simulées {#vis-sim}

<!-- paragraph -->

Dans cette section, nous simulons un ensemble de données simple avec un motif non linéaire pour la classification binaire.

<!-- paragraph -->

```{r}
sim.col <- 2
sim.row <- 100
set.seed(1)
features.hidden <- matrix(runif(sim.row*sim.col), sim.row, sim.col)
head(features.hidden)
```

<!-- paragraph -->

Dans la simulation, le tableau de données comporte les variables cachées (`hidden`) utilisées pour créer les étiquettes, mais elles ne sont pas disponibles pour l’apprentissage.
<!-- comment -->
La fonction latente/vraie utilisée pour la classification est la suivante :

<!-- paragraph -->

```{r}
bayes <- function(DT)DT[, (V1>0.2 & V2<0.8)]
library(data.table)
hidden.dt <- data.table(features.hidden)
label.vec <- ifelse(bayes(hidden.dt), 1, -1)
table(label.vec)
```

<!-- paragraph -->

Les étiquettes binaires ci-dessus sont générées à partir des variables cachées, mais pour l’apprentissage, nous n’avons accès qu’aux caractéristiques bruitées ci-dessous :

<!-- paragraph -->

```{r}
set.seed(1)
features.noisy <- features.hidden+rnorm(sim.row*sim.col, sd=0.05)
head(features.noisy)
```

<!-- paragraph -->

Pour tracer les données et visualiser le motif, nous utilisons le code ci-dessous :

<!-- paragraph -->

```{r}
library(animint2)
label.fac <- factor(label.vec)
sim.dt <- data.table(features.noisy, label.fac)
ggplot()+
  geom_point(aes(
    V1, V2, color=label.fac),
    data=sim.dt)+
  coord_equal()
```

<!-- paragraph -->

Le graphique ci-dessus représente chaque observation par un point, dont les deux caractéristiques figurent sur les  axes, et chaque étiquette par une couleur distincte.
<!-- comment -->
La partie inférieure droite de l’espace des caractéristiques a tendance à avoir des étiquettes positives, tandis que les zones gauche et supérieure ont des étiquettes négatives.
<!-- comment -->
C’est ce motif que le réseau neuronal devra apprendre.
<!-- comment -->
Pour former correctement un réseau neuronal, nous divisons les données en deux ensembles :

<!-- paragraph -->

- subtrain : utilisé pour calculer les gradients qui servent à mettre à jour les paramètres de pondération et les valeurs prédites.
<!-- comment -->
Avec suffisamment d’itérations/époques et un modèle de réseau neuronal assez puissant (nombre suffisant d’unités/couches cachées), il devrait être possible d’obtenir une prédiction parfaite sur l’ensemble de sous-entraînement (substrain).
<!-- comment -->
- validation : utilisé pour éviter le surapprentissage.
<!-- comment -->
En calculant l’erreur de prédiction sur cet ensemble et en choisissant le nombre d’itérations/époques de descente du gradient qui minimise l’erreur de validation, nous nous assurons que le modèle appris possède de bonnes propriétés de généralisation (il fournit de bonnes prédictions non seulement sur l’ensemble de sous-entraînement, mais aussi sur de nouveaux points de données comme dans l’ensemble de validation).

<!-- paragraph -->

```{r}
is.set.list <- list(
  validation=rep(c(TRUE,FALSE), l=nrow(features.noisy)))
is.set.list$subtrain <- !is.set.list$validation
set.vec <- ifelse(is.set.list$validation, "validation", "subtrain")
table(set.vec)
```

<!-- paragraph -->

Le code ci-dessus répartit aléatoirement les données aux ensembles de sous-entraînement et de validation.
<!-- comment -->
Ci-dessous, nous traçons les deux ensembles dans des facettes séparées :

<!-- paragraph -->

```{r}
sim.dt[, set := set.vec]
ggplot()+
  facet_grid(. ~ set, labeller=label_both)+
  geom_point(aes(
    V1, V2, color=label.fac),
    data=sim.dt)+
  coord_equal()
```

<!-- paragraph -->

## Visualisation de la fonction de classification optimale de Bayes {#vis-bayes-fun}

<!-- paragraph -->

Pour visualiser la limite de décision optimale/Bayes, il faut évaluer la fonction sur une grille de points 2D qui couvre l’espace des caractéristiques.
<!-- comment -->
Pour tracer cette grille, nous créons d’abord une liste contenant les deux grilles 1D pour chaque caractéristique.

<!-- paragraph -->

```{r}
(grid.list <- lapply(sim.dt[, .(V1, V2)], function(V){
  seq(min(V), max(V), l=30)
}))
```

<!-- paragraph -->

Ensuite, nous utilisons `CJ` (cross-join) pour créer un tableau de données représentant la grille 2D, pour laquelle nous évaluons la fonction de classification best/Bayes.

<!-- paragraph -->

```{r}
(grid.dt <- do.call(
  CJ, grid.list
)[
, bayes.num := ifelse(bayes(.SD), 1, -1)
][
, bayes.fac := factor(bayes.num)
][])
```

<!-- paragraph -->

La meilleure fonction de classification (`best`) est visualisée ci-dessous dans l’espace des variables d’entrée :

<!-- paragraph -->

```{r}
ggplot()+
  geom_tile(aes(
    V1, V2, fill=bayes.fac),
    color=NA,
    data=grid.dt)+
  geom_point(aes(
    V1, V2, fill=label.fac),
    color="black",
    data=sim.dt)+
  coord_equal()
```

<!-- paragraph -->

Le graphique ci-dessus montre que, même en utilisant la meilleure fonction possible, des erreurs de prédiction subsistent (points sur fond de couleur différente).
<!-- comment -->
Pour visualiser autrement la meilleure fonction de classification, on peut utiliser la limite de décision, le code ci-dessous permet de la calculer :

<!-- paragraph -->

```{r}
get_boundary <- function(score){
  contour.list <- contourLines(
    grid.list$V1, grid.list$V2, 
    matrix(
      score,
      length(grid.list$V1),
      length(grid.list$V2),
      byrow=TRUE),
    levels=0)
  if(length(contour.list)){
    data.table(contour.i=seq_along(contour.list))[, {
      with(contour.list[[contour.i]], data.table(level, x, y))
    }, by=contour.i]
  }
}
(bayes.contour.dt <- get_boundary(grid.dt$bayes.num))
```

<!-- paragraph -->

La meilleure limite de décision est visualisée dans l’espace des caractéristiques ci-dessous :

<!-- paragraph -->

```{r}
ggplot()+
  geom_path(aes(
    x, y, group=contour.i),
    data=bayes.contour.dt)+
  geom_point(aes(
    V1, V2, fill=label.fac),
    color="black",
    data=sim.dt)+
  coord_equal()
```

<!-- paragraph -->

## Propagation avant et arrière dans un modèle linéaire {#forward-back-prop-linear}

<!-- paragraph -->

Pour implémenter l’algorithme de descente de gradient pour l’apprentissage des paramètres du modèle de réseau neuronal, nous utiliserons un système simple d’auto-grad.
<!-- comment -->
Le principe de l’auto-grad consiste à définir une seule fois la structure du modèle et à utiliser cette structure pour  dériver les calculs de propagation vers l’avant (prédiction) et vers l’arrière (gradient).

<!-- paragraph -->

Nous utilisons ci-dessous un système auto-grad simple où chaque nœud du graphe de calcul est représenté par un environnement R (une structure de données mutable, nécessaire à la rétropropagation des gradients à tous les paramètres du modèle).
<!-- comment -->
La fonction ci-dessous est un constructeur pour l’élément de base du système auto-grad, un nœud dans le graphe de calcul :

<!-- paragraph -->

```{r}
new_node <- function(value, gradient=NULL, ...){
  node <- new.env()
  node$value <- value
  node$parent.list <- list(...)
  node$backward <- function(){
    grad.list <- gradient(node)
    for(parent.name in names(grad.list)){
      parent.node <- node$parent.list[[parent.name]]
      parent.node$grad <- grad.list[[parent.name]]
      parent.node$backward()
    }
  }
  node
}
```

<!-- paragraph -->

Le code de la fonction ci-dessus créé un nouvel environnement puis le remplit avec trois objets :

<!-- paragraph -->

- `value` est une matrice calculée par propagation vers l’avant à ce nœud du graphe de calcul.
<!-- comment -->
- `parent.list` est une liste de nœuds parents utilisés pour calculer `value`.
<!-- comment -->
- `backward` est une fonction qui doit être appelée par l’utilisateur sur le nœud final/de perte dans le graphe de calcul.
<!-- comment -->
Elle appelle `gradient` qui calcule le gradient de la perte par rapport aux nœuds parents, et le stocke dans l’attribut `grad` du nœud parent correspondant, puis appelle récursivement `backward` sur chaque nœud parent.

<!-- paragraph -->

Le type de nœud le plus simple est le nœud initial, défini par le code ci-dessous :

<!-- paragraph -->

```{r}
initial_node <- function(mat){
  new_node(mat, gradient=function(...)list())
}
```

<!-- paragraph -->

Le code ci-dessus indique qu’un nœud initial stocke simplement la matrice d’entrée `mat` comme valeur, et a une fonction `gradient` qui n’a  aucun effet (parce que les nœuds initiaux dans le graphe de calcul n’ont pas de parents pour lesquels des gradients pourraient être calculés).
<!-- comment -->
Le code ci-dessous définit `mm`, un nœud dans le graphe de calcul qui représente une multiplication de matrice :

<!-- paragraph -->

```{r}
mm <- function(feature.node, weight.node)new_node(
  cbind(1, feature.node$value) %*% weight.node$value,
  features=feature.node, 
  weights=weight.node,
  gradient=function(node)list(
    features=node$grad %*% t(weight.node$value),
    weights=t(cbind(1, feature.node$value)) %*% node$grad))
```

<!-- paragraph -->

La définition de `mm` ci-dessus suppose l’existence d’un nœud de pondération dont le nombre de lignes est le même que le nombre de colonnes (plus une pour l’ordonnée à l’origine) dans le nœud pour les variables d’entrée.
<!-- comment -->
Les calculs de valeur et de gradient des propagations avant reposent sur la multiplication matricielle.
<!-- comment -->
Par exemple, nous utilisons `mm` pour définir un modèle linéaire simple :

<!-- paragraph -->

```{r}
feature.node <- initial_node(features.noisy[is.set.list$subtrain,])
weight.node <- initial_node(rep(0, ncol(features.noisy)+1))
linear.pred.node <- mm(feature.node, weight.node)
str(linear.pred.node$value)
```

<!-- paragraph -->

On voit dans le code ci-dessus que la fonction `mm` renvoie un nœud représentant les valeurs prédites (un pour chaque ligne de la matrice des variables d’entrée).
<!-- comment -->
Pour exploiter les caractéristiques de gradient, nous avons besoin d’une fonction de perte qui, dans le cas de la classification binaire, est la perte logistique (entropie croisée).

<!-- paragraph -->

```{r}
log_loss <- function(pred.node, label.node)new_node(
  mean(log(1+exp(-label.node$value*pred.node$value))),
  pred=pred.node,
  label=label.node,
  gradient=function(...)list(
    pred=-label.node$value/(
      1+exp(label.node$value*pred.node$value)
    )/length(label.node$value)))
```

<!-- paragraph -->

Le code ci-dessus définit la perte logistique et le gradient, en supposant que l’étiquette est soit -1 soit 1, et que la prédiction est un nombre réel (pas nécessairement entre 0 et 1, il peut-être négatif).
<!-- comment -->
Le code ci-dessous crée des nœuds pour les étiquettes et la perte :

<!-- paragraph -->

```{r}
label.node <- initial_node(label.vec[is.set.list$subtrain])
loss.node <- log_loss(linear.pred.node, label.node)
loss.node$value
```

<!-- paragraph -->

Maintenant que la perte est calculée, nous pouvons déterminer le gradient de la perte par rapport aux pondérations, qui servira aux mises à jour pendant l’apprentissage.
<!-- comment -->
Rappelez-vous que nous devons maintenant appeler `backward` (sur la perte de sous-entrainement), qui devrait finalement stocker le gradient en tant que `weight.node$grad`.
<!-- comment -->
Ci-dessous, nous vérifions d’abord qu’il n’a pas encore été calculé, puis nous le calculons :

<!-- paragraph -->

```{r}
weight.node$grad
loss.node$backward()
weight.node$grad
```

<!-- paragraph -->

Puisque `loss.node` contient des références récursives à ses nœuds parents (y compris les prédictions et les pondérations), l’appel `backward` ci-dessus peut calculer et stocker aisément `weight.node$grad`, le gradient de la perte par rapport aux paramètres de pondération.
<!-- comment -->
Le gradient est la direction de la montée la plus raide, ce qui signifie que les pondérations de direction pourraient être modifiées pour maximiser la perte.
<!-- comment -->
Comme nous voulons minimiser la perte, l’algorithme d’apprentissage effectue des mises à jour dans la direction du gradient négatif, de la descente la plus raide.

<!-- paragraph -->

```{r}
(descent.direction <- -weight.node$grad)
```

<!-- paragraph -->

En descente de gradient pour ce modèle linéaire, nous mettons à jour le vecteur de pondération dans cette direction.
<!-- comment -->
Chaque mise à jour est appelée itération ou étape.
<!-- comment -->
Un petit pas dans cette direction garantit une diminution de la perte, mais s’il est trop petit, les progrès vers la minimisation de la perte seront limités.
<!-- comment -->
On ignore jusqu’où on doit d’aller dans cette direction, il faut donc généralement chercher dans une grille de tailles de pas (ou de taux d’apprentissage).
<!-- comment -->
On peut également effectuer une recherche linéaire, c’est-à-dire tracer le graphique suivant de la perte en fonction de la taille du pas, puis choisir la taille avec la perte minimale :

<!-- paragraph -->

```{r}
(line.search.dt <- data.table(step.size=seq(0, 10, l=101))[, .(
  loss=log_loss(mm(
    feature.node, 
    initial_node(weight.node$value+step.size*descent.direction)
  ), label.node)$value
), by=step.size])
line.search.min <- line.search.dt[which.min(loss)]
ggplot()+
  geom_line(aes(
    step.size, loss),
    data=line.search.dt)+
  geom_point(aes(
    step.size, loss),
    data=line.search.min)+
  geom_text(aes(
    step.size, loss, label=sprintf(
      "min loss=%f at step size=%.1f",
      loss, step.size)),
    data=line.search.min,
    hjust=0,
    vjust=1.5)
```

<!-- paragraph -->

Le graphique ci-dessus montre que la perte minimale se produit à une taille de pas d’environ 3, ce qui signifie que la recherche linéaire choisirait cette valeur pour la mise à jour/itération des paramètres de descente de gradient, avant de recalculer le gradient à l’itération suivante.

<!-- paragraph -->

## Apprentissage par réseau neuronal {#neural-network-learning}

<!-- paragraph -->

Définir un modèle linéaire dans la section précédente était relativement simple, car il n’y avait  qu’un paramètre de matrice de pondération (en fait, un vecteur de pondération, avec le même nombre d’éléments que le nombre de colonnes/caractéristiques, plus un pour l’ordonnée à l’origine).
<!-- comment -->
En revanche, un réseau neuronal a plus d’un paramètre de matrice de pondération à apprendre.
<!-- comment -->
Nous initialisons ces pondérations sous forme de nœuds dans le code ci-dessous :

<!-- paragraph -->

```{r}
new_weight_node_list <- function(units.per.layer, intercept=TRUE){
  weight.node.list <- list()
  for(layer.i in seq(1, length(units.per.layer)-1)){
    input.units <- units.per.layer[[layer.i]]+intercept
    output.units <- units.per.layer[[layer.i+1]]
    weight.mat <- matrix(
      rnorm(input.units*output.units), input.units, output.units)
    weight.node.list[[layer.i]] <- initial_node(weight.mat)
  }
  weight.node.list
}
(units.per.layer <- c(ncol(features.noisy), 40, 1))
(weight.node.list <- new_weight_node_list(units.per.layer))
lapply(weight.node.list, function(node)dim(node$value))
```

<!-- paragraph -->

La sortie ci-dessus montre que le réseau neuronal comporte une seule couche de 40 unités cachées, ce qui implique deux matrices de pondération à apprendre.
<!-- comment -->
Chacune d’elles est utilisée pour prédire les unités d’une couche donnée à partir des unités de la couche précédente.
<!-- comment -->
Pour apprendre une fonction de prédiction, qui est une fonction non linéaire des caractéristiques, chaque couche (sauf la dernière) doit avoir une fonction d’activation non linéaire, appliquée élément par élément aux unités, après la multiplication de la matrice.
<!-- comment -->

Par exemple, une fonction d’activation non linéaire courante et efficace est la ReLU (Rectified Linear Units), implémentée ci-dessous :

<!-- paragraph -->

```{r}
relu <- function(before.node)new_node(
  ifelse(before.node$value < 0, 0, before.node$value),
  before=before.node,
  gradient=function(node)list(
    before=ifelse(before.node$value < 0, 0, node$grad)))
hidden.before.act <- mm(feature.node, weight.node.list[[1]])
str(hidden.before.act$value)
hidden.before.act$value[1:5,1:5]
hidden.after.act <- relu(hidden.before.act)
hidden.after.act$value[1:5,1:5]
```

<!-- paragraph -->

Notez dans la sortie ci-dessus que l’activation ReLU ramène les valeurs négatives à zéro et maintient les valeurs positives.

<!-- paragraph -->

```{r}
(relu.dt <- data.table(
  input=seq(-5, 5, l=101)
)[, output := relu(initial_node(input))$value][])
ggplot()+
  ggtitle("L’activation ReLU est non linéaire")+
  geom_line(aes(
    input, output),
    data=relu.dt)
```

<!-- paragraph -->

Le dernier nœud nécessaire à l’implémentation de notre réseau neuronal est un nœud pour les prédictions, calculé par une boucle `for` sur les nœuds de pondération dans la fonction ci-dessous :

<!-- paragraph -->

```{r}
pred_node <- function(set.features){
  feature.node <- initial_node(set.features)
  for(layer.i in seq_along(weight.node.list)){
    weight.node <- weight.node.list[[layer.i]]
    before.node <- mm(feature.node, weight.node)
    feature.node <- if(layer.i < length(weight.node.list)){
      relu(before.node)
    }else{
      before.node
    }
  }
  feature.node
}
nn.pred.node <- pred_node(features.noisy[is.set.list$subtrain,])
str(nn.pred.node$value)
```

<!-- paragraph -->

La fonction `pred_node` est également utile pour calculer les prédictions sur la grille de caractéristiques, ce qui servira lors de la visualisation de la fonction apprise.

<!-- paragraph -->

```{r}
grid.mat <- grid.dt[, cbind(V1,V2)]
nn.grid.node <- pred_node(grid.mat)
str(nn.grid.node$value)
```

<!-- paragraph -->

Le code ci-dessous combine tous les éléments précédents dans un algorithme d’apprentissage par descente de gradient.
<!-- comment -->
Les hyperparamètres sont la taille du pas constant et le nombre maximal d’itérations.

<!-- paragraph -->

```{r}
step.size <- 0.5
max.iterations <- 1000
units.per.layer <- c(ncol(features.noisy), 40, 1)
loss.dt.list <- list()
err.dt.list <- list()
pred.dt.list <- list()
set.seed(10)
weight.node.list <- new_weight_node_list(units.per.layer)
for(iteration in 1:max.iterations){
  loss.node.list <- list()
  for(set in names(is.set.list)){
    is.set <- is.set.list[[set]]
    set.label.node <- initial_node(label.vec[is.set])
    set.features <- features.noisy[is.set,]
    set.pred.node <- pred_node(set.features)
    set.loss.node <- log_loss(set.pred.node, set.label.node)
    loss.node.list[[set]] <- set.loss.node
    set.pred.num <- ifelse(set.pred.node$value<0, -1, 1)
    is.error <- set.pred.num != set.label.node$value
    err.dt.list[[paste(iteration, set)]] <- data.table(
      iteration, set,
      set.features,
      label=set.label.node$value,
      pred.num=as.numeric(set.pred.num))
    loss.dt.list[[paste(iteration, set)]] <- data.table(
      iteration, set,
      mean.log.loss=set.loss.node$value,
      error.percent=100*mean(is.error))
  }
  grid.node <- pred_node(grid.mat)
  pred.dt.list[[paste(iteration)]] <- data.table(
    iteration,
    grid.dt,
    pred=as.numeric(grid.node$value))
  loss.node.list$subtrain$backward()#<-back-prop.
  for(layer.i in seq_along(weight.node.list)){
    weight.node <- weight.node.list[[layer.i]]
    weight.node$value <- #learning/param updates:
      weight.node$value-step.size*weight.node$grad
  }  
}
loss.dt <- rbindlist(loss.dt.list)
err.dt <- rbindlist(err.dt.list)
pred.dt <- rbindlist(pred.dt.list)
loss.tall <- melt(loss.dt, measure=c("mean.log.loss", "error.percent"))
loss.tall[, log10.iteration := log10(iteration)]
min.dt <- loss.tall[
, .SD[which.min(value)], by=.(set, variable)]
ggplot()+
  facet_grid(variable ~ ., scales="free")+
  scale_y_continuous("")+
  geom_line(aes(
    iteration, value, color=set),
    data=loss.tall)+
  geom_point(aes(
    iteration, value, fill=set),
    color="black",
    data=min.dt)
```

<!-- paragraph -->

Dans le code ci-dessus, nous avons enregistré les pertes et les prédictions pour toutes les itérations de la descente de gradient, mais nous ne visualisons que certaines d’entre elles dans le code ci-dessous, faute d’espace :

<!-- paragraph -->

```{r}
some <- function(DT)DT[iteration%in%c(1,5,10,50,100)]
err.dt[, prediction := ifelse(label==pred.num, "correct", "error")]
iteration.contours <- pred.dt[
, get_boundary(pred), by=.(iteration)]
some.loss <- some(loss.dt)
pred.dt[, norm.pred := pred/max(abs(pred)), by=.(iteration)]
some.pred <- some(pred.dt)
some.err <- some(err.dt)
some.contours <- some.pred[
, get_boundary(pred), by=.(iteration)]
ggplot()+
  facet_grid(set ~ iteration, labeller="label_both")+
  geom_tile(aes(
    V1, V2, fill=norm.pred),
    color=NA,
    data=some.pred)+
  geom_path(aes(
    x, y, group=contour.i),
    color="grey50",
    data=some.contours)+
  scale_fill_gradient2()+
  geom_point(aes(
    V1, V2, color=prediction, fill=label/2),
    size=2,
    data=some.err)+
  scale_color_manual(
    values=c(correct="white", error="black"))+
  coord_equal()+
  scale_y_continuous(breaks=seq(0,1,by=0.5))+
  scale_x_continuous(breaks=seq(0,1,by=0.5))
```

<!-- paragraph -->

Le graphique ci-dessus montre que les prédictions gagnent en précision à mesure que le nombre d’itérations augmente.
<!-- comment -->
Nous terminons la section par un graphique interactif dans lequel on peut cliquer sur la courbe des pertes pour sélectionner une itération de descente de gradient, dont la limite de décision correspondante s’affiche alors sur le graphique des prédictions.

<!-- paragraph -->

```{r ch18-nnet-vs-linear}
n.subtrain <- sum(is.set.list$subtrain)
loss.dt[, n.set := ifelse(
  set=="subtrain", n.subtrain, sim.row-n.subtrain
)][, error.count := n.set*error.percent/100]
it.by <- 10
some <- function(DT)DT[iteration %in% as.integer(
  seq(1, max.iterations, by=it.by))]
animint(
  title="Réseau de neurones vs modèle linéaire",
  out.dir="neural-networks-sim",
  loss=ggplot()+
    ggtitle("Courbes d’erreur, sélectionner le modèle et l’itération")+
    theme_bw()+
    theme_animint(width=600, height=350)+
    theme(panel.margin=grid::unit(1, "lines"))+
    facet_grid(variable ~ ., scales="free")+
    scale_y_continuous("")+
    scale_x_continuous(
      "Itération/époque d’entraînement")+
    geom_line(aes(
      iteration, value, color=set, group=set),
      data=loss.tall)+
    geom_point(aes(
      iteration, value, fill=set),
      color="black",
      data=min.dt)+
    geom_tallrect(aes(
      xmin=iteration-it.by/2, 
      xmax=iteration+it.by/2),
      alpha=0.5,
      clickSelects="iteration",
      data=some(loss.tall[set=="subtrain"])),
  data=ggplot()+
    ggtitle("Fonction apprise au modèle/à l’itération sélectionné(e)")+
    theme_bw()+
    theme_animint(width=600)+
    facet_grid(. ~ set, labeller="label_both")+
    geom_tile(aes(
      V1, V2, fill=norm.pred),
      color=NA,
      showSelected="iteration",
      data=some(pred.dt))+
    geom_text(aes(
      0.5, 1.1, label=paste0(
        "loss=", round(mean.log.loss, 4),
        ", ", error.count, "/", n.set, 
        " errors=", error.percent, "%")),
      showSelected="iteration",
      data=loss.dt)+
    geom_path(aes(
      x, y, group=contour.i),
      showSelected="iteration",
      color="grey50",
      data=some(iteration.contours))+
    geom_point(aes(
      V1, V2, fill=label/2, color=prediction),
      showSelected=c("iteration", "set"),
      size=4,
      data=some(err.dt))+
    scale_fill_gradient2(
      "Class/Score")+
    scale_color_manual(
      values=c(correct="white", error="black"))+
    scale_x_continuous(
      "Input/Feature 1")+
    scale_y_continuous(
      "Input/Feature 2")+
    coord_equal())
```

<!-- paragraph -->

## Résumé du chapitre et exercices {#ch18-exercises}

<!-- paragraph -->

Exercices :

<!-- paragraph -->

- Animez le nombre d’itérations.
<!-- comment -->
- Ajoutez des transitions fluides pour le nombre d’itérations.
<!-- comment -->
- Ajoutez une boucle `for` sur des graines aléatoires (ou des plis de validation croisée) à l’étape de division des données, et créez une visualisation qui montre l’impact sur les résultats.
<!-- comment -->
- Ajoutez une boucle `for` sur des graines aléatoires à l’étape d’initialisation de la matrice de pondération, et créez une visualisation qui montre comment cela affecte les résultats.
<!-- comment -->
- Calculez les résultats pour une autre architecture de réseau neuronal (et/ou un modèle linéaire, en ajoutant une boucle `for` sur différentes valeurs de `units.per.layer`).
<!-- comment -->
Ajoutez un graphique ou une facette permettant de sélectionner l’architecture du réseau neuronal et de comparer facilement la perte de validation minimale entre les modèles (par exemple, ajoutez des colonnes de facettes au graphique de perte et ajoutez des lignes horizontales pour mettre en évidence la perte minimale).
<!-- comment -->
- Modifiez l’algorithme d’apprentissage pour utiliser la recherche linéaire plutôt qu’une taille de pas constante, puis créez une visualisation qui compare les deux approches en termes de perte de validation minimale.

<!-- paragraph -->

Dans le [chapitre 19](/ch19), nous vous expliquerons comment visualiser les probabilités critiques (valeurs-p) d’un test statistique.
<!-- comment -->

<!-- paragraph -->


