---
title: Exemple de K-Voisins les plus proches
layout: default
output: bookdown::html_chapter
---



Traduction de l'[anglais](https://github.com/tdhock/animint-book/)
[Ch10-nearest-neighbors](https://raw.githubusercontent.com/tdhock/animint-book/master/Ch10-nearest-neighbors.Rmd)


<!-- paragraph -->

```{r setup, echo=FALSE}
knitr::opts_chunk$set(fig.path="Ch10-figures/")
```

<!-- paragraph -->

Dans ce chapitre, nous allons explorer plusieurs visualisations des données du classificateur des K-voisins les plus proches (KNN).

<!-- paragraph -->

Plan du chapitre :

<!-- paragraph -->

- Nous commencerons par la visualisation statique originale des données, repensée sous la forme de deux ggplots affichés par animint.
<!-- comment -->
Il y a un graphique de l'erreur de validation croisée 10 fois, et un graphique des prédictions du classificateur 7-voisins les plus proches.
<!-- comment -->
- Nous proposons une nouvelle conception qui permet de sélectionner le nombre de voisins utilisés pour les prédictions du modèle.
<!-- comment -->
- Nous proposons une deuxième refonte qui permet de sélectionner le nombre de plis utilisés pour calculer l'erreur de validation croisée.

<!-- paragraph -->

## Figure statique originale {#static}

<!-- paragraph -->

Nous commençons par reproduire une version statique de la figure 13.4 à partir de [Elements of Statistical Learning par Hastie et al](http://statweb.stanford.edu/~tibs/ElemStatLearn/) .
<!-- comment -->
Cette figure se compose de deux graphiques :

<!-- paragraph -->

![Viz KNN statique](Ch10-viz-static.png)

<!-- paragraph -->

A gauche : courbes d'erreur de classification, en fonction du nombre de voisins.

<!-- paragraph -->

- `geom_line` et `geom_point` pour les courbes d'erreur.
<!-- comment -->
- `geom_linerange` pour les barres d'erreur de la courbe d'erreur de validation.
<!-- comment -->
- `geom_hline` pour l'erreur de Bayes.
<!-- comment -->
- x = voisins.
<!-- comment -->
- y = pourcentage d'erreur.
<!-- comment -->
- couleur = type d'erreur.

<!-- paragraph -->

À droite : limites des données et des décisions dans l'espace bidimensionnel des caractéristiques d'entrée.

<!-- paragraph -->

- `geom_point` pour les points de données.
<!-- comment -->
- `geom_point` pour les prédictions de classification sur la grille en arrière-plan.
<!-- comment -->
- `geom_path` pour les limites de décision.
<!-- comment -->
- `geom_text` pour les taux d'erreur train/test/Bayes.

<!-- paragraph -->

### Tracé des courbes d'erreurs de classification {#static-error}

<!-- paragraph -->

Nous commençons par charger l'ensemble des données.

<!-- paragraph -->

```{r}
if(!file.exists("ESL.mixture.rda")){
  download.file(
    "https://web.stanford.edu/~hastie/ElemStatLearn/datasets/ESL.mixture.rda",
    "ESL.mixture.rda")
}
load("ESL.mixture.rda")
str(ESL.mixture)
```

<!-- paragraph -->

Nous utiliserons les éléments suivants de cet ensemble de données :

<!-- paragraph -->

- `x` la matrice d'entrée de l'ensemble de données d'apprentissage (200 observations x 2 caractéristiques numériques).
<!-- comment -->
- `y`, le vecteur de sortie de l'ensemble de données d'apprentissage (200 étiquettes de classe, soit 0 ou 1).
<!-- comment -->
- `xnew` La grille de points dans l'espace d'entrée où nous montrerons les prédictions du classificateur (6831 points de la grille x 2 caractéristiques numériques).
<!-- comment -->
- `prob` La probabilité réelle de la classe 1 à chacun des points de la grille (6831 valeurs numériques comprises entre 0 et 1).
<!-- comment -->
- `px1`, la grille de points pour le premier élément d'entrée (69 valeurs numériques comprises entre -2,6 et 4,2).
<!-- comment -->
Ces points seront utilisés pour calculer la limite de décision de Bayes à l'aide de la fonction contourLines.
<!-- comment -->
- `px2` la grille de points pour la deuxième caractéristique d'entrée (99 valeurs numériques comprises entre -2 et 2,9).
<!-- comment -->
- `means` les 20 centres des distributions normales dans le modèle de simulation (20 centres x 2 caractéristiques d'entrée).

<!-- paragraph -->

Tout d'abord, nous créons un ensemble de tests, en suivant le code d'exemple de `help(ESL.mixture)`.
<!-- comment -->
Notez que nous utilisons un `data.table` plutôt qu'un `data.frame` pour stocker ces big data, puisque `data.table` est souvent plus rapide et plus efficace en termes de mémoire pour les ensembles de données volumineux.

<!-- paragraph -->

```{r}
library(MASS)
library(data.table)
set.seed(123)
centers <- c(
  sample(1:10, 5000, replace=TRUE),
  sample(11:20, 5000, replace=TRUE))
mix.test <- mvrnorm(10000, c(0,0), 0.2*diag(2))
test.points <- data.table(
  mix.test + ESL.mixture$means[centers,],
  label=factor(c(rep(0, 5000), rep(1, 5000))))
test.points
```

<!-- paragraph -->

Nous créons ensuite un tableau de données qui comprend tous les points de test et les points de la grille, que nous utiliserons dans l'argument de test de la fonction knn.

<!-- paragraph -->

```{r}
pred.grid <- data.table(ESL.mixture$xnew, label=NA)
input.cols <- c("V1", "V2")
names(pred.grid)[1:2] <- input.cols
test.and.grid <- rbind(
  data.table(test.points, set="test"),
  data.table(pred.grid, set="grid"))
test.and.grid$fold <- NA
test.and.grid
```

<!-- paragraph -->

Nous assignons aléatoirement chaque observation de l'ensemble de données d'apprentissage à l'un des dix plis.

<!-- paragraph -->

```{r}
n.folds <- 10
set.seed(2)
mixture <- with(ESL.mixture, data.table(x, label=factor(y)))
mixture$fold <- sample(rep(1:n.folds, l=nrow(mixture)))
mixture
```

<!-- paragraph -->

Nous définissons les éléments suivants `OneFold` qui divise les 200 observations en un ensemble de formation et un ensemble de validation.
<!-- comment -->
Elle calcule ensuite la probabilité prédite par le classificateur des K-voisins les plus proches pour chacun des points de données dans tous les ensembles (formation, validation, test et grille).

<!-- paragraph -->

```{r}
OneFold <- function(validation.fold){
  set <- ifelse(mixture$fold == validation.fold, "validation", "train")
  fold.data <- rbind(test.and.grid, data.table(mixture, set))
  fold.data$data.i <- 1:nrow(fold.data)
  only.train <- subset(fold.data, set == "train")
  data.by.neighbors <- list()
  for(neighbors in seq(1, 30, by=2)){
    if(interactive())cat(sprintf(
      "n.folds=%4d validation.fold=%d neighbors=%d\n",
      n.folds, validation.fold, neighbors))
    set.seed(1)
    pred.label <- class::knn( # random tie-breaking.
      only.train[, input.cols, with=FALSE],
      fold.data[, input.cols, with=FALSE],
      only.train$label,
      k=neighbors,
      prob=TRUE)
    prob.winning.class <- attr(pred.label, "prob")
    fold.data$probability <- ifelse(
      pred.label=="1", prob.winning.class, 1-prob.winning.class)
    fold.data[, pred.label := ifelse(0.5 < probability, "1", "0")]
    fold.data[, is.error := label != pred.label]
    fold.data[, prediction := ifelse(is.error, "error", "correct")]
    data.by.neighbors[[paste(neighbors)]] <- 
      data.table(neighbors, fold.data)
  }#for(neighbors
  do.call(rbind, data.by.neighbors)
}#for(validation.fold
```

<!-- paragraph -->

Ci-dessous, nous exécutons la commande `OneFold` en parallèle à l'aide de la fonction `future` package.
<!-- comment -->
Notez que les plis de validation 1:10 seront utilisés pour calculer l'erreur de l'ensemble de validation.
<!-- comment -->
Le pli de validation 0 traite l'ensemble des 200 observations comme un ensemble d'entraînement et sera utilisé pour visualiser les limites de décision apprises du classificateur K-voisins les plus proches.

<!-- paragraph -->

```{r}
future::plan("multisession")
data.all.folds.list <- future.apply::future_lapply(
  0:n.folds, function(validation.fold){
    one.fold <- OneFold(validation.fold)
    data.table(validation.fold, one.fold)
  },
  future.seed = NULL)
(data.all.folds <- do.call(rbind, data.all.folds.list))
```

<!-- paragraph -->

Le tableau de données des prédictions contient près de 3 millions d'observations !
<!-- comment -->
Lorsqu'il y a autant de données, les visualiser toutes en même temps n'est ni pratique ni informatif.
<!-- comment -->
Au lieu de les visualiser toutes en même temps, nous allons calculer et tracer des statistiques sommaires.
<!-- comment -->
Dans le code ci-dessous, nous calculons la moyenne et l'erreur standard de l'erreur de classification pour chaque modèle (sur les 10 plis de validation).
<!-- comment -->
Il s'agit d'un exemple de la fonction [résumer un tableau de données idiome](Ch99-appendix.html#summarize-data-table) qui est généralement utile pour calculer des statistiques sommaires pour un tableau de données unique.

<!-- paragraph -->

```{r}
labeled.data <- data.all.folds[!is.na(label),]
error.stats <- labeled.data[, list(
  error.prop=mean(is.error)
  ), by=.(set, validation.fold, neighbors)]
validation.error <- error.stats[set=="validation", list(
  mean=mean(error.prop),
  sd=sd(error.prop)/sqrt(.N)
  ), by=.(set, neighbors)]
validation.error
```

<!-- paragraph -->

Nous construisons ci-dessous des tableaux de données pour l'erreur de Bayes (dont nous savons qu'elle est de 0,21 pour les données de l'exemple de mélange) et l'erreur de formation/essai.

<!-- paragraph -->

```{r}
Bayes.error <- data.table(
  set="Bayes",
  validation.fold=NA,
  neighbors=NA,
  error.prop=0.21)
Bayes.error
other.error <- error.stats[validation.fold==0,]
head(other.error)
```

<!-- paragraph -->

Ci-dessous, nous construisons une palette de couleurs à partir de `dput(RColorBrewer::brewer.pal(Inf, "Set1"))` et des palettes de types de lignes.

<!-- paragraph -->

```{r}
set.colors <- c(
  test="#377EB8", #blue
  validation="#4DAF4A",#green
  Bayes="#984EA3",#purple
  train="#FF7F00")#orange
classifier.linetypes <- c(
  Bayes="dashed",
  KNN="solid")
set.linetypes <- set.colors
set.linetypes[] <- classifier.linetypes[["KNN"]]
set.linetypes["Bayes"] <- classifier.linetypes[["Bayes"]]
cbind(set.linetypes, set.colors)
```

<!-- paragraph -->

Le code ci-dessous reproduit le tracé des courbes d'erreur de la figure originale.

<!-- paragraph -->

```{r}
library(animint2)
errorPlotStatic <- ggplot()+
  theme_bw()+
  geom_hline(aes(
    yintercept=error.prop, color=set, linetype=set),
    data=Bayes.error)+
  scale_color_manual(
    "error type", values=set.colors, breaks=names(set.colors))+
  scale_linetype_manual(
    "error type", values=set.linetypes, breaks=names(set.linetypes))+
  ylab("Misclassification Errors")+
  xlab("Number of Neighbors")+
  geom_linerange(aes(
    neighbors, ymin=mean-sd, ymax=mean+sd,
    color=set),
    data=validation.error)+
  geom_line(aes(
    neighbors, mean, linetype=set, color=set),
    data=validation.error)+
  geom_line(aes(
    neighbors, error.prop, group=set, linetype=set, color=set),
    data=other.error)+
  geom_point(aes(
    neighbors, mean, color=set),
    data=validation.error)+
  geom_point(aes(
    neighbors, error.prop, color=set),
    data=other.error)
errorPlotStatic
```

<!-- paragraph -->

### Tracé des frontières de décision dans l'espace des caractéristiques d'entrée. {#static-features}

<!-- paragraph -->

Pour la visualisation statique des données de l'espace des caractéristiques, nous ne montrons que le modèle avec 7 voisins.

<!-- paragraph -->

```{r}
show.neighbors <- 7
show.data <- data.all.folds[validation.fold==0 & neighbors==show.neighbors,]
show.points <- show.data[set=="train",]
show.points
```

<!-- paragraph -->

Ensuite, nous calculons les taux d'erreur de classification Train, Test et Bayes que nous afficherons en bas à gauche du tracé de l'espace des caractéristiques.

<!-- paragraph -->

```{r}
text.height <- 0.25
text.V1.prop <- 0
text.V2.bottom <- -2
text.V1.error <- -2.6
error.text <- rbind(
  Bayes.error,
  other.error[neighbors==show.neighbors,])
error.text[, V2.top := text.V2.bottom + text.height * (1:.N)]
error.text[, V2.bottom := V2.top - text.height]
error.text
```

<!-- paragraph -->

Nous définissons la fonction suivante que nous utiliserons pour calculer les limites de décision.

<!-- paragraph -->

```{r}
getBoundaryDF <- function(prob.vec){
  stopifnot(length(prob.vec) == 6831)
  several.paths <- with(ESL.mixture, contourLines(
    px1, px2,
    matrix(prob.vec, length(px1), length(px2)),
    levels=0.5))
  contour.list <- list()
  for(path.i in seq_along(several.paths)){
    contour.list[[path.i]] <- with(several.paths[[path.i]], data.table(
      path.i, V1=x, V2=y))
  }
  do.call(rbind, contour.list)
}
```

<!-- paragraph -->

Nous utilisons cette fonction pour calculer les limites de décision pour le classificateur appris des 7 plus proches voisins et pour le classificateur optimal de Bayes.

<!-- paragraph -->

```{r}
boundary.grid <- show.data[set=="grid",]
boundary.grid[, label := pred.label]
pred.boundary <- getBoundaryDF(boundary.grid$probability)
pred.boundary$classifier <- "KNN"
Bayes.boundary <- getBoundaryDF(ESL.mixture$prob)
Bayes.boundary$classifier <- "Bayes"
Bayes.boundary
```

<!-- paragraph -->

Ci-dessous, nous ne considérons que les points de la grille qui ne chevauchent pas les étiquettes de texte.

<!-- paragraph -->

```{r}
on.text <- function(V1, V2){
  V2 <= max(error.text$V2.top) & V1 <= text.V1.prop
}
show.grid <- boundary.grid[!on.text(V1, V2),]
show.grid
```

<!-- paragraph -->

Le nuage de points ci-dessous reproduit le classificateur des 7 plus proches voisins de la figure originale.

<!-- paragraph -->

```{r}
label.colors <- c(
  "0"="#377EB8",
  "1"="#FF7F00")
scatterPlotStatic <- ggplot()+
  theme_bw()+
  theme(axis.text=element_blank(),
        axis.ticks=element_blank(),
        axis.title=element_blank())+
  ggtitle("7-Nearest Neighbors")+
  scale_color_manual(values=label.colors)+
  scale_linetype_manual(values=classifier.linetypes)+
  geom_point(aes(
    V1, V2, color=label),
    size=0.2,
    data=show.grid)+
  geom_path(aes(
    V1, V2, group=path.i, linetype=classifier),
    size=1,
    data=pred.boundary)+
  geom_path(aes(
    V1, V2, group=path.i, linetype=classifier),
    color=set.colors[["Bayes"]],
    size=1,
    data=Bayes.boundary)+
  geom_point(aes(
    V1, V2, color=label),
    fill=NA,
    size=3,
    shape=21,
    data=show.points)+
  geom_text(aes(
    text.V1.error, V2.bottom, label=paste(set, "Error:")),
    data=error.text,
    hjust=0)+
  geom_text(aes(
    text.V1.prop, V2.bottom, label=sprintf("%.3f", error.prop)),
    data=error.text,
    hjust=1)
scatterPlotStatic
```

<!-- paragraph -->

### Graphiques combinés {#static-combined}

<!-- paragraph -->

Enfin, nous combinons les deux ggplots et les affichons sous forme d'animint.

<!-- paragraph -->

```{r Ch10-viz-static}
animint(errorPlotStatic, scatterPlotStatic)
```

<!-- paragraph -->

Cette visualisation des données comporte trois légendes interactives, mais elle est statique en ce sens qu'elle n'affiche que les prédictions du modèle des 7 plus proches voisins.

<!-- paragraph -->

## Sélectionner le nombre de voisins à l'aide de l'interactivité {#neighbors}

<!-- paragraph -->

Dans cette section, nous proposons une nouvelle conception interactive qui permet à l'utilisateur de sélectionner K, le nombre de voisins dans le classificateur K-Voisins les plus proches.

<!-- paragraph -->

![Viz KNN interactif](Ch10-viz-interactive.png)

<!-- paragraph -->

### Tracé cliquable des courbes d'erreur {#neighbors-error}

<!-- paragraph -->

Nous commençons par une refonte du graphique des courbes d'erreur.

<!-- paragraph -->

Notez les changements suivants :

<!-- paragraph -->

- ajouter un sélecteur pour le nombre de voisins ( `geom_tallrect` ).
<!-- comment -->
- changer la limite de décision de Bayes de `geom_hline` avec une entrée de légende, à un `geom_segment` avec une étiquette de texte.
<!-- comment -->
- ajouter une légende de type ligne pour distinguer les taux d'erreur des modèles Bayes et KNN.
<!-- comment -->
- changer les barres d'erreur ( `geom_linerange` ) en bandes d'erreur ( `geom_ribbon` ).

<!-- paragraph -->

Les seules nouvelles données que nous devons définir sont les points d'extrémité du segment que nous utiliserons pour tracer la frontière de décision de Bayes.
<!-- comment -->
Notez que nous redéfinissons également l'ensemble "test" pour souligner le fait que l'erreur de Bayes est le meilleur taux d'erreur réalisable pour les données de test.

<!-- paragraph -->

```{r}
Bayes.segment <- data.table(
  Bayes.error,
  classifier="Bayes",
  min.neighbors=1,
  max.neighbors=29)
Bayes.segment$set <- "test"
```

<!-- paragraph -->

Nous ajoutons également aux tableaux de données une variable erreur qui contient l'erreur de prédiction des modèles de type K-voisins les plus proches.
<!-- comment -->
Cette variable d'erreur sera utilisée pour la légende du type de ligne.

<!-- paragraph -->

```{r}
validation.error$classifier <- "KNN"
other.error$classifier <- "KNN"
```

<!-- paragraph -->

Nous redéfinissons le graphique des courbes d'erreur ci-dessous.
<!-- comment -->
Notez que

<!-- paragraph -->

- Nous utilisons showSelected dans `geom_text` et `geom_ribbon` afin qu'elles soient masquées lorsque l'on clique sur les légendes interactives.
<!-- comment -->
- Nous utilisons clickSelects dans `geom_tallrect` pour sélectionner le nombre de voisins.
<!-- comment -->
Les geoms cliquables doivent être placés en dernier (couche supérieure) afin de ne pas être masqués par les geoms non cliquables (couches inférieures).

<!-- paragraph -->

```{r}
set.colors <- c(
  test="#984EA3",#purple
  validation="#4DAF4A",#green
  Bayes="#984EA3",#purple
  train="black")
errorPlot <- ggplot()+
  ggtitle("Select number of neighbors")+
  theme_bw()+
  theme_animint(height=500)+
  geom_text(aes(
    min.neighbors, error.prop,
    color=set, label="Bayes"),
    showSelected="classifier",
    hjust=1,
    data=Bayes.segment)+
  geom_segment(aes(
    min.neighbors, error.prop, 
    xend=max.neighbors, yend=error.prop,
    color=set,
    linetype=classifier),
    showSelected="classifier", 
    data=Bayes.segment)+
  scale_color_manual(values=set.colors, breaks=names(set.colors))+
  scale_fill_manual(values=set.colors)+
  guides(fill="none", linetype="none")+
  scale_linetype_manual(values=classifier.linetypes)+
  ylab("Misclassification Errors")+
  scale_x_continuous(
    "Number of Neighbors",
    limits=c(-1, 30),
    breaks=c(1, 10, 20, 29))+
  geom_ribbon(aes(
    neighbors, ymin=mean-sd, ymax=mean+sd,
    fill=set),
    showSelected=c("classifier", "set"),
    alpha=0.5,
    color="transparent",
    data=validation.error)+
  geom_line(aes(
    neighbors, mean, color=set,
    linetype=classifier),
    showSelected="classifier", 
    data=validation.error)+
  geom_line(aes(
    neighbors, error.prop, group=set, color=set,
    linetype=classifier),
    showSelected="classifier", 
    data=other.error)+
  geom_tallrect(aes(
    xmin=neighbors-1, xmax=neighbors+1),
    clickSelects="neighbors",
    alpha=0.5,
    data=validation.error)
errorPlot
```

<!-- paragraph -->

### Tracé de l'espace des caractéristiques qui montre le nombre de voisins sélectionnés. {#neighbors-features}

<!-- paragraph -->

Ensuite, nous nous concentrons sur une refonte du graphique de l'espace des caractéristiques.
<!-- comment -->
Dans la section précédente, nous n'avons considéré que le sous-ensemble de données du modèle à 7 voisins.
<!-- comment -->
Notre nouvelle conception comprend les changements suivants :

<!-- paragraph -->

- Nous utilisons les voisins comme variable showSelected.
<!-- comment -->
- Nous ajoutons une légende pour indiquer les points de données d'entraînement mal classés.
<!-- comment -->
- Nous utilisons des coordonnées à espacement égal afin que la distance visuelle (pixels) soit la même que la distance euclidienne dans l'espace des caractéristiques.

<!-- paragraph -->

```{r}
show.data <- data.all.folds[validation.fold==0,]
show.points <- show.data[set=="train",]
show.points
```

<!-- paragraph -->

Ci-dessous, nous calculons les limites de décision prédites séparément pour chaque modèle de K-voisins les plus proches.

<!-- paragraph -->

```{r}
boundary.grid <- show.data[set=="grid",]
boundary.grid[, label := pred.label]
show.grid <- boundary.grid[!on.text(V1, V2),]
pred.boundary <- boundary.grid[, getBoundaryDF(probability), by=neighbors]
pred.boundary$classifier <- "KNN"
pred.boundary
```

<!-- paragraph -->

Au lieu d'afficher le nombre de voisins dans le titre du graphique, nous créons ci-dessous un `geom_text` qui sera mis à jour en fonction du nombre de voisins sélectionnés.

<!-- paragraph -->

```{r}
show.text <- show.grid[, list(
  V1=mean(range(V1)), V2=3.05), by=neighbors]
```

<!-- paragraph -->

Nous calculons ci-dessous la position du texte en bas à gauche, que nous utiliserons pour afficher le taux d'erreur du modèle sélectionné.

<!-- paragraph -->

```{r}
other.error[, V2.bottom := rep(
  text.V2.bottom + text.height * 1:2, l=.N)]
```

<!-- paragraph -->

Ci-dessous, nous redéfinissons les données de l'erreur de Bayes sans colonne de voisins, afin qu'elles apparaissent dans chaque sous-ensemble showSelected.

<!-- paragraph -->

```{r}
Bayes.error <- data.table(
  set="Bayes",
  error.prop=0.21)
```

<!-- paragraph -->

Enfin, nous redéfinissons le ggplot, en utilisant neighbors comme variable showSelected dans les geoms point, chemin et texte.

<!-- paragraph -->

```{r}
scatterPlot <- ggplot()+
  ggtitle("Mis-classification errors in train set")+
  theme_bw()+
  theme_animint(width=500, height=500)+
  xlab("Input feature 1")+
  ylab("Input feature 2")+
  coord_equal()+
  scale_color_manual(values=label.colors)+
  scale_linetype_manual(values=classifier.linetypes)+
  geom_point(aes(
    V1, V2, color=label),
    showSelected="neighbors",
    size=0.2,
    data=show.grid)+
  geom_path(aes(
    V1, V2, group=path.i, linetype=classifier),
    showSelected="neighbors",
    size=1,
    data=pred.boundary)+
  geom_path(aes(
    V1, V2, group=path.i, linetype=classifier),
    color=set.colors[["test"]],
    size=1,
    data=Bayes.boundary)+
  geom_point(aes(
    V1, V2, color=label,
    fill=prediction),
    showSelected="neighbors",
    size=3,
    shape=21,
    data=show.points)+
  scale_fill_manual(values=c(error="black", correct="transparent"))+
  geom_text(aes(
    text.V1.error, text.V2.bottom, label=paste(set, "Error:")),
    data=Bayes.error,
    hjust=0)+
  geom_text(aes(
    text.V1.prop, text.V2.bottom, label=sprintf("%.3f", error.prop)),
    data=Bayes.error,
    hjust=1)+
  geom_text(aes(
    text.V1.error, V2.bottom, label=paste(set, "Error:")),
    showSelected="neighbors",
    data=other.error,
    hjust=0)+
  geom_text(aes(
    text.V1.prop, V2.bottom, label=sprintf("%.3f", error.prop)),
    showSelected="neighbors",
    data=other.error,
    hjust=1)+
  geom_text(aes(
    V1, V2,
    label=paste0(
      neighbors,
      " nearest neighbor",
      ifelse(neighbors==1, "", "s"),
      " classifier")),
    showSelected="neighbors",
    data=show.text)
```

<!-- paragraph -->

Avant de compiler la visualisation des données interactive, nous imprimons un ggplot statique avec une facette pour chaque valeur de voisins.

<!-- paragraph -->

```{r}
scatterPlot+
  facet_wrap("neighbors")+
  theme(panel.margin=grid::unit(0, "lines"))
```

<!-- paragraph -->

### Visualisation des données interactive combinée {#neighbors-combined}

<!-- paragraph -->

Enfin, nous combinons les deux graphiques dans une visualisation des données unique avec les voisins comme variable de sélection.

<!-- paragraph -->

```{r Ch10-viz-neighbors}
animint(
  errorPlot,
  scatterPlot,
  first=list(neighbors=7),
  time=list(variable="neighbors", ms=3000))
```

<!-- paragraph -->

Notez que les voisins sont utilisés comme variable temporelle, de sorte que l'animation montre les prédictions des différents modèles.

<!-- paragraph -->

## Sélectionner le nombre de plis de validation croisée à l'aide de l'interactivité {#folds}

<!-- paragraph -->

Dans cette section, nous discutons d'une deuxième refonte qui permet à l'utilisateur de sélectionner le nombre de plis utilisés pour calculer la courbe d'erreur de validation.

<!-- paragraph -->

La boucle for ci-dessous calcule la courbe d'erreur de validation pour plusieurs valeurs différentes de `n.folds`.

<!-- paragraph -->

```{r}
error.by.folds <- list()
error.by.folds[["10"]] <- data.table(n.folds=10, validation.error)
for(n.folds in c(3, 5, 15)){
  set.seed(2)
  mixture <- with(ESL.mixture, data.table(x, label=factor(y)))
  mixture$fold <- sample(rep(1:n.folds, l=nrow(mixture)))
  only.validation.list <- future.apply::future_lapply(
    1:n.folds, function(validation.fold){
      one.fold <- OneFold(validation.fold)
      data.table(validation.fold, one.fold[set=="validation"])
    })
  only.validation <- do.call(rbind, only.validation.list)
  only.validation.error <- only.validation[, list(
    error.prop=mean(is.error)
  ), by=.(set, validation.fold, neighbors)]
  only.validation.stats <- only.validation.error[, list(
    mean=mean(error.prop),
    sd=sd(error.prop)/sqrt(.N)
  ), by=.(set, neighbors)]
  error.by.folds[[paste(n.folds)]] <-
    data.table(n.folds, only.validation.stats, classifier="KNN")
}
validation.error.several <- do.call(rbind, error.by.folds)
```

<!-- paragraph -->

Le code ci-dessous calcule le minimum de la courbe d'erreur pour chaque valeur de `n.folds`.

<!-- paragraph -->

```{r}
min.validation <- validation.error.several[, .SD[which.min(mean),], by=n.folds]
```

<!-- paragraph -->

Le code ci-dessous crée un nouveau graphique de courbe d'erreur à deux facettes.

<!-- paragraph -->

```{r}
facets <- function(df, facet){
  data.frame(df, facet=factor(facet, c("n.folds", "Misclassification Errors")))
}
errorPlotNew <- ggplot()+
  ggtitle("Select number of folds and neighbors")+
  theme_bw()+
  theme_animint(height=500)+
  theme(panel.margin=grid::unit(0, "cm"))+
  facet_grid(facet ~ ., scales="free")+
  geom_text(aes(
    min.neighbors, error.prop,
    color=set, label="Bayes"),
    showSelected="classifier",
    hjust=1,
    data=facets(Bayes.segment, "Misclassification Errors"))+
  geom_segment(aes(
    min.neighbors, error.prop, 
    xend=max.neighbors, yend=error.prop,
    color=set,
    linetype=classifier),
    showSelected="classifier",                
    data=facets(Bayes.segment, "Misclassification Errors"))+
  scale_color_manual(values=set.colors, breaks=names(set.colors))+
  scale_fill_manual(values=set.colors, breaks=names(set.colors))+
  guides(fill="none", linetype="none")+
  scale_linetype_manual(values=classifier.linetypes)+
  ylab("")+
  scale_x_continuous(
    "Number of Neighbors",
    limits=c(-1, 30),
    breaks=c(1, 10, 20, 29))+
  geom_ribbon(aes(
    neighbors, ymin=mean-sd, ymax=mean+sd,
    fill=set),
    showSelected=c("classifier", "set", "n.folds"),
    alpha=0.5,
    color="transparent",
    data=facets(validation.error.several, "Misclassification Errors"))+
  geom_line(aes(
    neighbors, mean, color=set,
    linetype=classifier),
    showSelected=c("classifier", "n.folds"),
    data=facets(validation.error.several, "Misclassification Errors"))+
  geom_line(aes(
    neighbors, error.prop, group=set, color=set,
    linetype=classifier),
    showSelected="classifier", 
    data=facets(other.error, "Misclassification Errors"))+
  geom_tallrect(aes(
    xmin=neighbors-1, xmax=neighbors+1),
    clickSelects="neighbors",
    alpha=0.5,
    data=validation.error)+
  geom_point(aes(
    neighbors, n.folds, color=set),
    clickSelects="n.folds",
    size=9,
    data=facets(min.validation, "n.folds"))
```

<!-- paragraph -->

Le code ci-dessous prévisualise le nouveau tracé de la courbe d'erreur, en ajoutant une facette supplémentaire pour la variable showSelected.

<!-- paragraph -->

```{r}
errorPlotNew+facet_grid(facet ~ n.folds, scales="free")
```

<!-- paragraph -->

Le code ci-dessous crée une visualisation des données interactive à l'aide du nouveau tracé de la courbe d'erreur.

<!-- paragraph -->

```{r Ch10-viz-folds}
animint(
  errorPlotNew,
  scatterPlot,
  first=list(neighbors=7, n.folds=10))
```

<!-- paragraph -->

## Résumé du chapitre et exercices {#exercises}

<!-- paragraph -->

Nous avons montré comment ajouter deux fonctionnalités interactives à une visualisation des données des prédictions du modèle des K-voisins les plus proches.
<!-- comment -->
Nous avons commencé par une visualisation des données statique qui ne montrait que les prédictions du modèle des 7 plus proches voisins.
<!-- comment -->
Ensuite, nous avons créé une nouvelle conception interactive qui permettait de sélectionner K, le nombre de voisins.
<!-- comment -->
Nous avons procédé à une autre refonte en ajoutant une facette permettant de sélectionner le nombre de plis de validation croisée.

<!-- paragraph -->

Exercices :

<!-- paragraph -->

- Faites en sorte que les taux d'erreur du texte en bas à gauche du deuxième graphique soient cachés après avoir cliqué sur les entrées de la légende pour Bayes, train, test.
<!-- comment -->
Conseil : vous pouvez soit utiliser un `geom_text` avec `showSelected=c(selectorNameColumn="selectorValueColumn")` (comme expliqué dans [Chapitre 14](Ch14-PeakSegJoint.html) ) ou deux `geom_text` chacun avec un paramètre showSelected différent.
<!-- comment -->
- La colonne probabilité du tableau de données show.grid est la probabilité prédite de la classe 1.
<!-- comment -->
Comment modifieriez-vous la visualisation pour montrer la probabilité prédite plutôt que la classe prédite à chaque point de la grille ?
<!-- comment -->
La principale difficulté est que la probabilité est une variable numérique, mais ggplot2 impose que chaque échelle soit continue ou discrète (pas les deux).
<!-- comment -->
Vous pourriez utiliser une échelle de remplissage continue, mais vous devriez alors utiliser une échelle différente pour montrer la variable de prédiction.
<!-- comment -->
- Ajoutez un nouveau graphique qui montre les tailles relatives des ensembles de formation, de validation et de test.
<!-- comment -->
Assurez-vous que la taille tracée des ensembles de validation et d'entraînement change en fonction de la valeur sélectionnée pour le paramètre `n.folds`.
<!-- comment -->
- Jusqu'à présent, les graphiques de l'espace des caractéristiques ne montraient que les prédictions et les erreurs du modèle pour l'ensemble des données de train (validation.fold==0).
<!-- comment -->
Créer une nouvelle conception qui inclut un nouveau graphique ou une nouvelle facette pour sélectionner validation.fold, et un graphique de l'espace des caractéristiques à facettes (une facette pour l'ensemble de données de formation, une facette pour l'ensemble de données de validation).

<!-- paragraph -->

Suivant, [Chapitre 11](Ch11-lasso.html) explique comment visualiser le Lasso, un modèle d'apprentissage automatique.

<!-- paragraph -->


