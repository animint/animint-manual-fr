# Détection supervisée des points de changement

<!-- paragraph -->

```{r setup, echo=FALSE}
knitr::opts_chunk$set(fig.path="ch16-figures/")
```

<!-- paragraph -->

Dans ce chapitre, nous allons explorer plusieurs visualisations des données des modèles de détection supervisée des points de changement.

<!-- paragraph -->

Plan du chapitre :

<!-- paragraph -->

- Nous commençons par effectuer plusieurs visualisations statiques de la `intreg` données.
<!-- comment -->
- Nous créons ensuite une visualisation interactive dans laquelle un graphique peut être cliqué pour sélectionner le nombre de points de changement/segments, et l'autre graphique montre le modèle correspondant.
<!-- comment -->
- Nous terminons en montrant une visualisation statique du modèle de régression linéaire de la marge maximale, et en suggérant des exercices pour créer une version interactive.

<!-- paragraph -->

## Figures statiques {#static-change-point}

<!-- paragraph -->

Nous commençons par charger le fichier `intreg` données.

<!-- paragraph -->

```{r intreg}
library(animint2)
data(intreg)
library(data.table)
lapply(intreg, function(df)data.table(df)[1:2])
```

<!-- paragraph -->

Comme indiqué ci-dessus, il s'agit d'une liste nommée de 7 cadres de données apparentés.
<!-- comment -->
Nous commençons notre exploration de ces données en traçant les signaux dans des facettes séparées.

<!-- paragraph -->

```{r signals}
data.color <- "grey50"
gg.signals <- ggplot()+
  theme_bw()+
  facet_grid(signal ~ ., scales="free")+
  geom_point(aes(
    base/1e6, logratio,
    showSelected="signal"),
    color=data.color,
    data=intreg$signals)
gg.signals
```

<!-- paragraph -->

Chaque point de données tracé ci-dessus montre une mesure approximative du nombre de copies d'ADN (logratio), en fonction de la position des bases sur un chromosome.
<!-- comment -->
Ces données proviennent d'analyses à haut débit qui sont importantes pour diagnostiquer certains types de cancer comme le neuroblastome.

<!-- paragraph -->

Une partie importante du diagnostic consiste à détecter les "points de rupture" ou les changements abrupts au sein d'un chromosome donné (panel).
<!-- comment -->
Le graphique ci-dessus montre clairement qu'il y a plusieurs points de rupture dans ces données.
<!-- comment -->
En particulier, le signal 4.2 semble avoir trois points de rupture, le signal 4.3 semble en avoir un, etc.
<!-- comment -->
En fait, ces données proviennent de médecins de l'Institut Curie (Paris, France) qui ont annoté visuellement les régions avec et sans points de cassure.
<!-- comment -->
Ces données sont disponibles en tant que `intreg$annotations` et sont tracées ci-dessous.

<!-- paragraph -->

```{r annotations}
breakpoint.colors <- c(
  "1breakpoint"="#ff7d7d",
  "0breakpoints"='#f6f4bf')
gg.ann <- gg.signals+
  scale_fill_manual(values=breakpoint.colors)+
  geom_tallrect(aes(
    xmin=first.base/1e6, xmax=last.base/1e6,
    fill=annotation),
    color="grey",
    alpha=0.5,
    data=intreg$annotations)
gg.ann
```

<!-- paragraph -->

Le graphique ci-dessus montre en jaune les régions où les médecins ont déterminé qu'il n'y a pas de point de rupture significatif, et en rouge les régions où il y a un point de rupture.
<!-- comment -->
L'objectif de l'analyse de ces données est d'apprendre à partir des données étiquetées limitées (régions colorées) et de fournir des prédictions cohérentes sur les points de rupture (même dans les régions non étiquetées).

<!-- paragraph -->

Afin de détecter ces points de rupture, nous avons ajusté certains modèles de segmentation de vraisemblance maximale, en utilisant l'algorithme efficace implémenté dans le logiciel `jointseg::Fpsn`.
<!-- comment -->
Les moyens des segments sont disponibles dans `intreg$segments` et les points d'arrêt prédits sont disponibles dans `intreg$breaks`.
<!-- comment -->
Pour chaque signal, il existe une séquence de modèles de 1 à 20 segments.
<!-- comment -->
Zoomons d'abord sur un signal :

<!-- paragraph -->

```{r one}
sig.name <- "4.2"
show.segs <- 7
sig.labels <- subset(intreg$annotations, signal==sig.name)
gg.one <- ggplot()+
  theme_bw()+
  theme(panel.margin=grid::unit(0, "lines"))+
  geom_tallrect(aes(
    xmin=first.base/1e6, xmax=last.base/1e6,
    fill=annotation),
    color="grey",
    alpha=0.5,
    data=sig.labels)+
  geom_point(aes(
    base/1e6, logratio),
    color=data.color,
    data=subset(intreg$signals, signal==sig.name))+
  scale_fill_manual(values=breakpoint.colors)
gg.one
```

<!-- paragraph -->

Nous traçons ci-dessous certains de ces modèles pour l'un des signaux :

<!-- paragraph -->

```{r models}
sig.segs <- data.table(
  intreg$segments)[signal == sig.name & segments <= show.segs]
sig.breaks <- data.table(
  intreg$breaks)[signal == sig.name & segments <= show.segs]
model.color <- "green"
gg.models <- gg.one+
  facet_grid(segments ~ .)+
  geom_segment(aes(
    first.base/1e6, mean,
    xend=last.base/1e6, yend=mean),
    color=model.color,
    data=sig.segs)+
  geom_vline(aes(
    xintercept=base/1e6),
    color=model.color,
    linetype="dashed",
    data=sig.breaks)
gg.models
```

<!-- paragraph -->

Le graphique ci-dessus montre les modèles de segmentation de vraisemblance maximale en vert (de un à six segments).
<!-- comment -->
Ci-dessous, nous utilisons le modèle `penaltyLearning::labelError` pour calculer l'erreur d'étiquette, qui quantifie quels modèles sont en accord avec quelles étiquettes.

<!-- paragraph -->

```{r labelerr}
sig.models <- data.table(segments=1:show.segs, signal=sig.name)
sig.errors <- penaltyLearning::labelError(
  sig.models, sig.labels, sig.breaks,
  change.var="base",
  label.vars=c("first.base", "last.base"),
  model.vars="segments",
  problem.vars="signal")
```

<!-- paragraph -->

Le `sig.errors$label.errors` tableau de données contient une ligne pour chaque combinaison (modèle,étiquette).
<!-- comment -->
Le tableau`status` peut être utilisée pour afficher l'erreur d'étiquette : `false negative` pour trop peu de changements, `false positive` pour trop de changements, ou `correct` pour le bon nombre de modifications.

<!-- paragraph -->

```{r plotlabelerr}
gg.models+
  geom_tallrect(aes(
    xmin=first.base/1e6, xmax=last.base/1e6,
    linetype=status),
    data=sig.errors$label.errors,
    color="black",
    size=1,
    fill=NA)+
  scale_linetype_manual(
    "error type",
    values=c(
      correct=0,
      "false negative"=3,
      "false positive"=1))
```

<!-- paragraph -->

En examinant le graphique des erreurs d'étiquettes ci-dessus, il est clair que le modèle à quatre segments devrait être sélectionné, car il permet d'obtenir des erreurs d'étiquettes nulles.
<!-- comment -->
Un certain nombre de critères peuvent être utilisés pour sélectionner le meilleur modèle.
<!-- comment -->
Une façon d'y parvenir est de sélectionner le modèle avec $s$ segments est $S^*(\\lambda)=L\_s + \\lambda*s$, où $L_s$ est la perte totale du modèle avec $s$ segments, et $\lambda$ est une pénalité non négative.
<!-- comment -->
Dans le graphique ci-dessous, nous montrons la fonction de sélection du modèle. $S^*(\lambda)$ pour cet ensemble de données :

<!-- paragraph -->

```{r selection}
sig.selection <- data.table(
  intreg$selection)[signal == sig.name & segments <= show.segs]
gg.selection <- ggplot()+
  theme_bw()+
  geom_segment(aes(
    min.L, segments,
    xend=max.L, yend=segments),
    data=sig.selection)+
  xlab("log(lambda)")
gg.selection
```

<!-- paragraph -->

Le graphique ci-dessus montre clairement que la fonction de sélection du modèle est décroissante.
<!-- comment -->
Dans la section suivante, nous réalisons une version interactive de ces deux graphiques dans laquelle nous pouvons cliquer sur le graphique de sélection de modèle afin de sélectionner le modèle.

<!-- paragraph -->

## Figures interactives pour un signal {#interactive-one}

<!-- paragraph -->

Nous allons créer une figure interactive pour un signal en ajoutant un `geom_tallrect()` avec `clickSelects=segments` au graphique ci-dessus :

<!-- paragraph -->

```{r selectionClick}
interactive.selection <- gg.selection+
  geom_tallrect(aes(
    xmin=min.L, xmax=max.L),
    clickSelects="segments",
    data=sig.selection,
    color=NA,
    fill="black",
    alpha=0.5)
interactive.selection
```

<!-- paragraph -->

Nous allons combiner cela avec la version non facettée du graphique données/modèles ci-dessous, dans lequel nous avons ajouté `showSelected=segments` aux geoms des modèles :

<!-- paragraph -->

```{r selectionData}
interactive.models <- gg.one+
  geom_segment(aes(
    first.base/1e6, mean,
    xend=last.base/1e6, yend=mean),
    showSelected="segments",
    color=model.color,
    data=sig.segs)+
  geom_vline(aes(
    xintercept=base/1e6),
    showSelected="segments",
    color=model.color,
    linetype="dashed",
    data=sig.breaks)+
  geom_tallrect(aes(
    xmin=first.base/1e6, xmax=last.base/1e6,
    linetype=status),
    showSelected="segments",
    data=sig.errors$label.errors,
    size=2,
    color="black",
    fill=NA)+
  scale_linetype_manual(
    "error type",
    values=c(
      correct=0,
      "false negative"=3,
      "false positive"=1))
interactive.models
```

<!-- paragraph -->

Bien entendu, le graphique ci-dessus n'est pas très informatif car il n'est pas interactif.
<!-- comment -->
Ci-dessous, nous combinons les deux ggplots interactifs en un seul animint lié :

<!-- paragraph -->

```{r interactiveOne}
animint(
  models=interactive.models+
    ggtitle("Selected model"),
  selection=interactive.selection+
    ggtitle("Click to select number of segments"))
```

<!-- paragraph -->

Notez que dans la visualisation des données ci-dessus, le modèle à 6 segments ne peut être sélectionné pour aucune valeur de lambda. Il n'est donc pas possible de cliquer sur le graphique pour sélectionner ce modèle.
<!-- comment -->
Cependant, il est possible de sélectionner le modèle en utilisant le menu de sélection des segments (cliquez sur "Afficher les menus de sélection" au bas de l'image de données).

<!-- paragraph -->

## Graphique de régression de la marge maximale statique {#max-margin}

<!-- paragraph -->

Une autre partie de cet ensemble de données est `intreg$intervals` qui comporte une ligne pour chaque signal.
<!-- comment -->
Les colonnes`min.L` et `max.L` indiquent les valeurs min/max de l'intervalle cible, qui correspond à la plage la plus large de valeurs de log(pénalité) avec des erreurs d'étiquette minimales.
<!-- comment -->
Nous traçons ci-dessous cet intervalle en fonction d'une caractéristique des données (logarithme du nombre de points de données) :

<!-- paragraph -->

```{r intervals}
gg.intervals <- ggplot()+
  geom_segment(aes(
    feature, min.L,
    xend=feature, yend=max.L),
    size=2,
    data=intreg$intervals)+
  geom_text(aes(
    feature, min.L, label=signal,
    color=ifelse(signal==sig.name, "black", "grey50")),
    vjust=1,
    data=intreg$intervals)+
  scale_color_identity()+
  ylab("output log(lambda)")+
  xlab("input feature x")
gg.intervals
```

<!-- paragraph -->

Les intervalles cibles dans le graphique ci-dessus indiquent la région de l'espace log(lambda) qui sélectionnera un modèle avec des erreurs d'étiquette minimales.
<!-- comment -->
Il y a un intervalle pour chaque signal ; nous avons fait un animint dans la section précédente pour le signal indiqué en noir.
<!-- comment -->
Des algorithmes d'apprentissage automatique peuvent être utilisés pour trouver une fonction de pénalité qui coupe chacun des intervalles et maximise la marge (la distance entre la fonction de régression et la limite de l'intervalle le plus proche).
<!-- comment -->
Les données pour la fonction de régression linéaire de la marge maximale sont dans `intreg$model` ce qui est illustré dans le tracé ci-dessous :

<!-- paragraph -->

```{r maxMargin}
gg.mm <- gg.intervals+
  geom_segment(aes(
    min.feature, min.L,
    xend=max.feature, yend=max.L,
    linetype=line),
    color="red",
    size=1,
    data=intreg$model)+
  scale_linetype_manual(
    values=c(
      regression="solid",
      margin="dotted",
      limit="dashed"))
gg.mm
```

<!-- paragraph -->

Le graphique ci-dessus montre la fonction de régression linéaire de la marge maximale f(x) sous la forme d'une ligne rouge continue.
<!-- comment -->
Il est clair qu'elle coupe chacun des intervalles cibles noirs et maximise la marge (lignes pointillées verticales rouges).
<!-- comment -->
Pour plus d'arguments sur le thème de la détection supervisée des points de changement, voir [mon tutoriel useR 2017](https://github.com/tdhock/change-tutorial).

<!-- paragraph -->

Maintenant que vous savez comment visualiser chacune des sept parties du `intreg` de données, le reste du chapitre est consacré à des exercices.

<!-- paragraph -->

## Résumé du chapitre et exercices {#ch16-exercises}

<!-- paragraph -->

Exercices :

<!-- paragraph -->

- Ajouter un `geom_text()` qui affiche le nom du signal actuellement sélectionné en haut du graphique, en `interactive.models` dans la première animation ci-dessus.
<!-- comment -->
- Créez une animation avec deux graphiques qui montre l'ensemble de données correspondant à chaque intervalle sur le graphique de régression de la marge maximale.
<!-- comment -->
L'un des graphiques doit montrer une version interactive du graphique de régression de la marge maximale où vous pouvez cliquer sur un intervalle pour sélectionner un signal.
<!-- comment -->
L'autre graphique doit afficher l'ensemble des données pour le signal sélectionné.
<!-- comment -->
- Dans l'animint que vous avez créé dans l'exercice précédent, ajoutez un troisième graphique avec la fonction de sélection de modèle pour le signal actuellement sélectionné.
<!-- comment -->
- Refondez l'animint précédent de sorte qu'au lieu d'utiliser un troisième graphique, ajoutez une facette au graphique de régression de la marge maximale de sorte que les axes log(lambda) soient tracés.
<!-- comment -->
Ajoutez une autre facette qui indique le nombre d'étiquettes incorrectes (`intreg$selection$cost`) pour chaque valeur de log(lambda).
<!-- comment -->
- Ajouter des geoms pour sélectionner le nombre de segments.
<!-- comment -->
En cliquant sur le tracé de sélection du modèle, on devrait sélectionner le nombre de segments, ce qui devrait mettre à jour le modèle affiché et les erreurs d'étiquette sur le graphique des données pour le signal actuellement sélectionné.
<!-- comment -->
En outre, ajouter une indication visuelle du modèle sélectionné sur le graphique de régression de la marge maximale.
<!-- comment -->
Le résultat devrait ressembler à quelque chose comme [comme ceci](https://rcdata.nau.edu/genomic-ml/animint-gallery/2016-01-28-Max-margin-interval-regression-for-supervised-segmentation-model-selection/index.html).
<!-- comment -->
- Créez une autre visualisation des données en commençant par la facette `gg.signals` au début de ce chapitre.
<!-- comment -->
Ajouter un graphique permettant de sélectionner le nombre de segments pour chaque signal.
<!-- comment -->
Pour chaque signal dans le graphique à facettes des données, montrez le modèle actuellement sélectionné pour ce signal (il devrait y avoir une variable de sélection distincte pour chaque signal -- vous pouvez utiliser les variables nommées `clickSelects` et `showSelected` comme expliqué dans [chapitre 14](/ch14)).
<!-- comment -->
Le résultat devrait ressembler à quelque chose comme [comme ceci](https://rcdata.nau.edu/genomic-ml/animint-gallery/2016-11-10-Max-margin-supervised-penalty-learning-for-peak-detection-in-ChIP-seq-data/index.html).

<!-- paragraph -->

Suivant, [Chapitre 17](/ch17) explique comment visualiser l'algorithme d'agrégation des K-moyennes.

<!-- paragraph -->


