# Agrégation par K-means (groupe)

<!-- paragraph -->

```{r setup, echo=FALSE}
knitr::opts_chunk$set(fig.path="ch17-figures/")
```

<!-- paragraph -->

Dans ce chapitre, nous allons explorer plusieurs visualisations des données de l'agrégation (groupe) par K-moyennes, qui est un algorithme d'apprentissage non supervisé.

<!-- paragraph -->

Plan du chapitre :

<!-- paragraph -->

- Nous commençons par visualiser deux caractéristiques des données de l'iris.
<!-- comment -->
- Nous choisissons trois points de données aléatoires à utiliser comme centres d'agrégation (groupe).
<!-- comment -->
- Nous montrons comment toutes les distances entre les points de données et les centres d'agrégation (groupe) peuvent être calculées et visualisées.
<!-- comment -->
- Nous terminons par une visualisation de l'évolution des paramètres du modèle k-means à chaque itération.

<!-- paragraph -->

## Visualisation des données de l'iris avec des étiquettes {#viz-iris}

<!-- paragraph -->

Nous commençons par une visualisation typique des données de l'iris, comprenant une légende de couleurs pour indiquer les Espèces.

<!-- paragraph -->

```{r}
library(animint2)
color.code <- c(
  setosa="#1B9E77",
  versicolor="#D95F02",
  virginica="#7570B3",
  "1"="#E7298A",
  "2"="#66A61E",
  "3"="#E6AB02", 
  "4"="#A6761D")
ggplot()+
  scale_color_manual(values=color.code)+
  geom_point(aes(
    Petal.Length, Petal.Width, color=Species),
    data=iris)+
  coord_equal()
```

<!-- paragraph -->

Nous allons illustrer l'algorithme d'agrégation (groupe) K-means à l'aide de ces deux dimensions,

<!-- paragraph -->

```{r, results=TRUE}
data.mat <- as.matrix(iris[,c("Petal.Width","Petal.Length")])
head(data.mat)
str(data.mat)
```

<!-- paragraph -->

Pour exécuter K-means, l'hyperparamètre du nombre d'agrégations (K) doit être fixé à l'avance.
<!-- comment -->
Ensuite, K points de données aléatoires sont sélectionnés comme centres d'agrégation initiaux,

<!-- paragraph -->

```{r}
K <- 3
library(data.table)
data.dt <- data.table(data.mat)
set.seed(3)
centers.dt <- data.dt[sample(1:.N, K)]
(centers.mat <- as.matrix(centers.dt))
centers.dt[, cluster := factor(1:K)]
centers.dt
gg.centers <- ggplot()+
  scale_color_manual(values=color.code)+
  geom_point(aes(
    Petal.Length, Petal.Width),
    color="grey50",
    data=data.dt)+
  geom_point(aes(
    Petal.Length, Petal.Width, color=cluster),
    data=centers.dt)+
  coord_equal()
gg.centers
```

<!-- paragraph -->

Ci-dessus, nous avons affiché les deux ensembles de données (centres d'agrégation et données) à l'aide de deux instances de `geom_point()`.
<!-- comment -->
Nous calculons ci-dessous la distance entre chaque point de données et chaque centre d'agrégation (groupe),

<!-- paragraph -->

```{r}
pairs.dt <- data.table(expand.grid(
  centers.i=1:nrow(centers.mat),
  data.i=1:nrow(data.mat)))
```

<!-- paragraph -->

Ces éléments peuvent être visualisés à l'aide d'un `geom_point()`,

<!-- paragraph -->

```{r}
seg.dt <- pairs.dt[, data.table(
  data.i,
  data=data.mat[data.i,],
  center=centers.mat[centers.i,])]
gg.centers+
  geom_segment(aes(
    data.Petal.Length, data.Petal.Width,
    xend=center.Petal.Length, yend=center.Petal.Width),
    size=1,
    data=seg.dt)
```

<!-- paragraph -->

Il y a `r nrow(seg.dt)` segments surreprésentés ci-dessus, de sorte que l'interactivité serait utile pour mettre l'accent sur les segments connectés à un point de données particulier.
<!-- comment -->
Pour ce faire, nous créons un fichier`data.i` variable de sélection,

<!-- paragraph -->

```{r ch17-kmeans-distances}
animint(
  ggplot()+
    theme_bw()+
    theme_animint(height=300, width=640)+
    scale_color_manual(values=color.code)+
    scale_x_continuous(breaks=seq(1,7,by=0.5))+
    scale_y_continuous(breaks=seq(0, 2.5, by=0.5))+
    geom_point(aes(
      Petal.Length, Petal.Width, color=cluster),
      size=4,
      data=centers.dt)+
    geom_segment(aes(
      data.Petal.Length, data.Petal.Width,
      xend=center.Petal.Length, yend=center.Petal.Width),
      size=1,
      showSelected="data.i",
      data=seg.dt)+
    geom_point(aes(
      Petal.Length, Petal.Width),
      clickSelects="data.i",
      size=2,
      color="grey50",
      data=data.table(data.mat, data.i=1:nrow(data.mat))))
```

<!-- paragraph -->

Dans la visualisation des données ci-dessus, vous pouvez cliquer sur un point de données pour afficher les distances entre ce point de données et chaque centre d'agrégation (groupe).

<!-- paragraph -->

Exercices pour cette section :

<!-- paragraph -->

- modifiez les échelles x/y de façon à ce que les mêmes tics soient représentés.
<!-- comment -->
- modifier la couleur de chaque segment pour qu'elle corresponde à l'agrégation (groupe) correspondante.
<!-- comment -->
- ajouter une infobulle qui indique la valeur de la distance.
<!-- comment -->
- faire dépendre la largeur du segment de son optimalité (le segment connecté au centre de l'agrégation la plus proche devrait être mis en valeur avec une plus grande largeur).

<!-- paragraph -->

## Visualisation des itérations de l'algorithme {#viz-iterations}

<!-- paragraph -->

Ensuite, nous calculons le centre d'agrégation le plus proche pour chaque point de données,

<!-- paragraph -->

```{r}
pairs.dt[, error := rowSums(
(data.mat[data.i,]-centers.mat[centers.i,])^2)]
(closest.dt <- pairs.dt[, .SD[which.min(error)], by=data.i])
(closest.data <- closest.dt[, .(
  data.dt[data.i],
  cluster=factor(centers.i)
)])
(both.dt <- rbind(
  data.table(type="centers", centers.dt),
  data.table(type="data", closest.data)))
ggplot()+
  scale_fill_manual(values=color.code)+
  scale_color_manual(values=c(centers="black", data="grey"))+
  scale_size_manual(values=c(centers=5, data=3))+
  geom_point(aes(
    Petal.Length, Petal.Width, fill=cluster, size=type, color=type),
    data=both.dt)+
  coord_equal()+
  theme_bw()
```

<!-- paragraph -->

Ensuite, nous mettons à jour les centres d'agrégation (groupe),

<!-- paragraph -->

```{r}
new.centers <- closest.dt[, data.table(
  t(colMeans(data.dt[data.i]))
), by=.(cluster=centers.i)]
(new.both <- rbind(
  data.table(type="centers", new.centers),
  data.table(type="data", closest.data)))
ggplot()+
  scale_fill_manual(values=color.code)+
  scale_color_manual(values=c(centers="black", data="grey"))+
  scale_size_manual(values=c(centers=5, data=3))+
  geom_point(aes(
    Petal.Length, Petal.Width, fill=cluster, size=type, color=type),
    data=new.both)+
  coord_equal()+
  theme_bw()
```

<!-- paragraph -->

Les visualisations ci-dessus montrent donc les étapes de la méthode k-means : (1) mise à jour de l'agrégation sur la base du centre le plus proche, puis (2) mise à jour du centre sur la base des données affectées à cette agrégation.
<!-- comment -->
Pour visualiser plusieurs itérations des deux étapes ci-dessus, nous pouvons utiliser une boucle for,

<!-- paragraph -->

```{r}
set.seed(3)
centers.dt <- data.dt[sample(1:.N, K)]
(centers.mat <- as.matrix(centers.dt))
data.and.centers.list <- list()
iteration.error.list <- list()
for(iteration in 1:20){
  pairs.dt[, error := {
    rowSums((data.mat[data.i,]-centers.mat[centers.i,])^2)
  }]
  closest.dt <- pairs.dt[, .SD[which.min(error)], by=data.i]
  iteration.error.list[[iteration]] <- data.table(
    iteration, error=sum(closest.dt[["error"]]))
  iteration.both <- rbind(
    data.table(type="centers", centers.dt, cluster=1:K),
    closest.dt[, data.table(
      type="data", data.dt[data.i], cluster=factor(centers.i))])
  data.and.centers.list[[iteration]] <- data.table(
    iteration, iteration.both)
  new.centers <- closest.dt[, data.table(
    t(colMeans(data.dt[data.i]))
  ), keyby=.(cluster=centers.i)]
  centers.dt <- new.centers[, names(centers.dt), with=FALSE]
  centers.mat <- as.matrix(centers.dt)
}
(data.and.centers <- do.call(rbind, data.and.centers.list))
(iteration.error <- do.call(rbind, iteration.error.list))
```

<!-- paragraph -->

Nous commençons par créer un graphique d'ensemble avec une courbe d'erreur qui servira à sélectionner la taille du modèle,

<!-- paragraph -->

```{r}
gg.err <- ggplot()+
  theme_bw()+
  geom_point(aes(
    iteration, error),
    data=iteration.error)+
  make_tallrect(iteration.error, "iteration", alpha=0.3)
```

<!-- paragraph -->

Nous créons également un graphique qui indique l'itération en cours,

<!-- paragraph -->

```{r}
gg.iteration <- ggplot()+
  scale_fill_manual(values=color.code)+
  scale_color_manual(values=c(centers="black", data=NA))+
  scale_size_manual(values=c(centers=5, data=2))+
  geom_point(aes(
    Petal.Length, Petal.Width, fill=cluster, size=type, color=type),
    showSelected="iteration",
    data=data.and.centers)+
  coord_equal()+
  theme_bw()
gg.iteration
```

<!-- paragraph -->

La combinaison des deux graphiques permet d'obtenir une visualisation des données interactive,

<!-- paragraph -->

```{r ch17-kmeans-iterations}
animint(gg.err, gg.iteration)
```

<!-- paragraph -->

## Résumé du chapitre et exercices {#ch17-exercises}

<!-- paragraph -->

Exercices :

<!-- paragraph -->

- Faire en sorte que les centres apparaissent toujours devant (au-dessus) des données.
<!-- comment -->
- Ajouter des transitions graduelles.
<!-- comment -->
- Ajout d'une animation sur la variable d'itération.
<!-- comment -->
- Le code actuel a fixé le nombre maximum d'itérations, il est donc possible que les dernières itérations ne progressent pas.
<!-- comment -->
Par exemple, dans l'image ci-dessus, l'itération 16 a été la dernière à entraîner une diminution de l'erreur (les itérations 17 à 20 n'ont entraîné aucune diminution).
<!-- comment -->
Modifiez le code pour qu'il arrête l'itération s'il n'y a pas de diminution de l'erreur.
<!-- comment -->
- La viz actuelle n'a qu'un seul cadre d'animation (`showSelected` sous-ensemble) par itération (la réalisation ou d'un sous-ensemble est avant sa mise à jour).
<!-- comment -->
Ajoutez un autre cadre d'animation qui montre la moyenne après la mise à jour.
<!-- comment -->
- Ajoutez des segments interactifs qui montrent la distance entre chaque point de données et chaque centre d'agrégation (comme dans la première animation de cette page).
<!-- comment -->
- Ajoutez les fonctionnalités décrites dans les exercices de la section précédente sur cette page.
<!-- comment -->
- Calculer les résultats pour plusieurs graines aléatoires différentes, puis afficher les taux d'erreur pour chaque graine sur le graphique d'aperçu des erreurs, et permettre à l'utilisateur de sélectionner n'importe lequel de ces résultats.
<!-- comment -->
- Calculer les résultats pour plusieurs nombres différents d'agrégations (K).
<!-- comment -->
Calculer l'indice de Rand ajusté en utilisant `pdfCluster::adj.rand.index(species, cluster)` pour chaque K et graine aléatoire différents.
<!-- comment -->
Ajouter un graphique d'ensemble qui montre la valeur ARI de chaque modèle, et permet de sélectionner le nombre d'agrégations (groupes).
<!-- comment -->
- Effectuez une visualisation similaire en utilisant un autre ensemble de données tel que `data("penguins", package="palmerpenguins")`.

<!-- paragraph -->

Suivant, [Chapitre 18](/ch18) explique comment visualiser l'algorithme d'apprentissage par descente de gradient pour l'apprentissage des réseaux neuronaux.

<!-- paragraph -->


